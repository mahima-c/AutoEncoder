{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "encoder.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJEaPn6Oh5J31HXKUzPPit",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahima-c/AutoEncoder/blob/main/encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg5mUhSDB9Yz"
      },
      "source": [
        "from tensorflow.keras import Model\r\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, Flatten, Dense\r\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6ehtvqn8jZM"
      },
      "source": [
        "class Autoencoder:\r\n",
        "  \"\"\"\r\n",
        "  Autoender represent deep convolution autoencoder with mirror image of encoder and decoder unit \r\n",
        "  \"\"\"\r\n",
        "  def __init__(self,input_shape,conv_filter,conv_kernal,conv_stride,latend_space_dim):\r\n",
        "          self.input_shape=input_shape#[28,28,1]\r\n",
        "          self.conv_filter=conv_filter#[2,4,8]\r\n",
        "          self.conv_kernal=conv_kernal#[3,5,3]\r\n",
        "          self.conv_stride=conv_stride#[1 ,2 ,2]\r\n",
        "          self.latend_space_dim=latend_space_dim\r\n",
        "          self.encoder=None\r\n",
        "          self.decoder=None\r\n",
        "          self.model=None\r\n",
        "\r\n",
        "          self._num_conv_layer=len(conv_filter)\r\n",
        "          self._shape_before_bottleneck = None\r\n",
        "          self._build()\r\n",
        "\r\n",
        "\r\n",
        "  def summary(self):\r\n",
        "        self.encoder.summary()  \r\n",
        "\r\n",
        "  def _build(self):  \r\n",
        "        self._build_encoder()   \r\n",
        "        # self._build_decoder()   \r\n",
        "        # self._build_autoencoder()   \r\n",
        "\r\n",
        "\r\n",
        "  def _build_encoder(self):\r\n",
        "        encoder_input = self._add_encoder_input()\r\n",
        "        conv_layers = self._add_conv_layers(encoder_input)\r\n",
        "        bottleneck = self._add_bottleneck(conv_layers)\r\n",
        "        self.encoder = Model(encoder_input, bottleneck, name=\"encoder\")\r\n",
        "\r\n",
        "  def _add_encoder_input(self):\r\n",
        "            return Input(shape=self.input_shape, name=\"encoder_input\")\r\n",
        "\r\n",
        "  def _add_conv_layers(self,encoder_input):\r\n",
        "        \"create all conv layer in encoder\"\r\n",
        "        x=encoder_input\r\n",
        "        for layer_index in range(self._num_conv_layer):\r\n",
        "            x = self._add_conv_layer(layer_index, x)\r\n",
        "        return x  \r\n",
        "      # x is graph of layer\r\n",
        "  def _add_conv_layer(self, layer_index, x): \r\n",
        "        \"\"\"Add a convolutional block to a graph of layers, consisting of\r\n",
        "            conv 2d + ReLU + batch normalization.\r\n",
        "            \"\"\"\r\n",
        "        layer_number=layer_index+1    \r\n",
        "        conv_layer=Conv2D(filters=self.conv_filter[layer_index],\r\n",
        "                          kernel_size=self.conv_kernal[layer_index],\r\n",
        "                          strides=self.conv_stride[layer_index],\r\n",
        "                          padding='same',\r\n",
        "                          name=f\"encoder_conv_layer_{layer_number}\"\r\n",
        "                                      )  \r\n",
        "        x = conv_layer(x) \r\n",
        "        x= ReLU(name=f\"encoder_relu_{layer_number}\")(x) \r\n",
        "        x = BatchNormalization(name=f\"encoder_bn_{layer_number}\")(x)\r\n",
        "        return x\r\n",
        "        \r\n",
        "  def _add_bottleneck(self, x):\r\n",
        "      \"\"\"Flatten data and add bottleneck (Dense layer).\"\"\"\r\n",
        "      self._shape_before_bottleneck = K.int_shape(x)[1:] \r\n",
        "        #for store shape before because that need in decoder part for mirror image[batch size,shape=7,7,18]\r\n",
        "      x = Flatten()(x)\r\n",
        "      x = Dense(self.latend_space_dim, name=\"encoder_output\")(x)\r\n",
        "      return x\r\n",
        "          \r\n",
        "\r\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flXs5NefITmk",
        "outputId": "0930025d-c6a7-47ae-d7d4-410f31210dce"
      },
      "source": [
        "if __name__ == \"__main__\":\r\n",
        "    autoencoder = Autoencoder(\r\n",
        "        input_shape=(28, 28, 1),\r\n",
        "        conv_filter=(32, 64, 64, 64),\r\n",
        "        conv_kernal=(3, 3, 3, 3),\r\n",
        "        conv_stride=(1, 2, 2, 1),\r\n",
        "        latend_space_dim=2\r\n",
        "        \r\n",
        "    )\r\n",
        "    autoencoder.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "encoder_conv_layer_1 (Conv2D (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "encoder_relu_1 (ReLU)        (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "encoder_bn_1 (BatchNormaliza (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "encoder_conv_layer_2 (Conv2D (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "encoder_relu_2 (ReLU)        (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "encoder_bn_2 (BatchNormaliza (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "encoder_conv_layer_3 (Conv2D (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "encoder_relu_3 (ReLU)        (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "encoder_bn_3 (BatchNormaliza (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "encoder_conv_layer_4 (Conv2D (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "encoder_relu_4 (ReLU)        (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "encoder_bn_4 (BatchNormaliza (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "encoder_output (Dense)       (None, 2)                 6274      \n",
            "=================================================================\n",
            "Total params: 99,842\n",
            "Trainable params: 99,394\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}